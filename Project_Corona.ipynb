{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the spread of COVID-19 based on European traffic data during summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data\n",
    "\n",
    "- Our World in Data COVID-19 dataset\n",
    "    - Data on deaths in different countries.\n",
    "\n",
    "\n",
    "- Google's traffic data \n",
    "    - Google provides anonymized insights from products such as Google Maps for researchers to help them to make critical analysis to combat COVID-19. \n",
    "    - Google has divided their traffic data into six traffic components: \n",
    "        1. retail \\& recreation\n",
    "            - places like restaurants, cafes, shopping centers, theme parks, museums, libraries and movie theaters\n",
    "        2. grocery \\& pharmacy\n",
    "            - places like grocery markets, food warehouses, farmers markets, specialty food shops, drug stores and pharmacies\n",
    "        3. parks\n",
    "            - places like national parks, public beaches, marinas, dog parks, plazas and public gardens\n",
    "        4. transit stations\n",
    "            - places like public transport hubs such as subway, bus and train stations\n",
    "        5. workplaces \n",
    "            - places of work\n",
    "        6. residential \n",
    "            -  places of residence\n",
    "     \n",
    "  - These components do not tell anything how much time people spend in each section on average but they still give a lot of information how people's traffic behavior changed during the pandemic\n",
    " \n",
    " - The traffic data's baseline is counted as a median value of multiple days. Day-to-day changes should not be emphasized too much because they are effected on many different factors, f.e. the weather and public events.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. Moral behind the Bayesian model\n",
    "\n",
    "\n",
    "- Getting the traffic data down slows down the spread of the virus. \n",
    "    - Several articles (Ferretti et al 2020, ECDC report, LSHTM report) have pointed out pre-symptomatic and asymptomatic  infections  play  a  significant  role  in  the  spread  of  COVID-19.  Indeed,  this observation  is  an  argument  it  may  not  be  enough  to  get  the  symptomatic  cases  to  stay at  home. Also  governmental  restrictions  should  be  implemented  to  get peopleâ€™s movement down and furthermore the pandemic under control.\n",
    "    - Essentially, the reason to implement non-pharmaceutical interventions is to get people's traffic data down!\n",
    "\n",
    "\n",
    "- There are multiple reasons why it makes sense to analyse European countries in this research\n",
    "    - COVID-19 hit European countries badly during autumn\n",
    "    - European governments have similar capabilities to restrict their citizens movement in comparison to many countries, f.e. China\n",
    "    - European countries adapted suppression strategy instead of mitigation one\n",
    "    \n",
    "    \n",
    "- There are many major differences between European countries which effect on the spread of COVID-19\n",
    "    - Examples: different age distributions, different population densities in cities, cultural differences\n",
    "    - Therefore comparisons between European countries should be avoided\n",
    "\n",
    "    \n",
    "- The COVID-19-case data is not reliable at least as the only measure about the development of the epidemic. COVID-19-death data has many benefits compared to the COVID-19 case data! \n",
    "    - The amount of testing varies a lot between countries\n",
    "    - Also using death data over infected data has the benefit that deaths measures much better country's success against the epidemic than infections\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.3. Motivation, research goals\n",
    "\n",
    "\n",
    "1. To create a model which predicts the spread of the epidemic well based on the traffic data and data on deaths.\n",
    "\n",
    "2. Based on the created model, trying to understand which of these Google's traffic components predicted the spread of COVID-19 in different European countries\n",
    "\n",
    "\n",
    "### 1.4.  Structure\n",
    "\n",
    "\n",
    "\n",
    "1. Introduction\n",
    "    - Describes the essentials of this notebook\n",
    "2. Getting an overview how COVID-19-cases and people's traffic behavior developed during the pandemic\n",
    "3. Bayesian model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Libraries used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pystan\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import stan_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Parameters which need to be defined manually\n",
    "\n",
    "- All the parameters, which need to be defined manually, are here\n",
    "\n",
    "\n",
    "- During text there are detailed explanations what these parameters are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "\n",
    "# There is COVID-19-data from February until now\n",
    "observations_start_date = datetime.datetime(2020, 2, 1, 0, 0)\n",
    "observations_end_date = datetime.datetime(2020, 11, 15, 0, 0)\n",
    "\n",
    "# However, the data analysis of this notebook concentrates on autumn months, i.e. on so called tail\n",
    "tail_start_date = datetime.datetime(2020, 9, 1, 0, 0)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# European countries ordered by population\n",
    "european_countries = [\n",
    "    'Germany', 'United Kingdom', 'France', 'Italy', 'Spain', \n",
    "    'Ukraine', 'Poland', 'Romania','Netherlands', 'Belgium', \n",
    "    'Greece', 'Sweden', 'Portugal', 'Hungary', 'Belarus', \n",
    "    'Austria', 'Switzerland', 'Bulgaria', 'Serbia', 'Denmark', \n",
    "    'Finland', 'Norway', 'Ireland', 'Croatia', 'Moldova', \n",
    "    'Bosnia and Herzegovina', 'Lithuania', 'Slovenia', 'Estonia' ]\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# Window size for convolution\n",
    "w = 7\n",
    "\n",
    "# Death limit\n",
    "d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 European countries analysed in this notebook.\n",
      "The length of the whole interval: 288\n",
      "The length of the tail interval: 75\n"
     ]
    }
   ],
   "source": [
    "# Follows directly from manual definitions \n",
    "num_countries = len(european_countries)\n",
    "whole_interval_len = (observations_end_date - observations_start_date).days \n",
    "tail_interval_len = (observations_end_date - tail_start_date).days \n",
    "date_list = [observations_start_date + datetime.timedelta(days=x) for x in range(whole_interval_len)]\n",
    "\n",
    "print(\"There are \" + str(num_countries) + \" European countries analysed in this notebook.\")\n",
    "print(\"The length of the whole interval: \" + str(whole_interval_len))\n",
    "print(\"The length of the tail interval: \" + str(tail_interval_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition: Autumn interval $\\tau_{\\text{autumn}}$\n",
    "\n",
    "Let's denote the autumn interval with $\\tau_{\\text{autumn}} = \\{ 0,1,2, \\dots, 75 \\}$. Indeed $t = 0$ corresponds the date 1.9.2020, $t = 1$ corresponds the date 2.9.2020 and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Adding previously cleaned data to dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe df_countries\n",
    "\n",
    "- The length of this dataframe is 'num_countries'. Indeed, for each country there is one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>population_in_millions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>83783945</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>67886004</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>65273512</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>60461828</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>46754783</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>43733759</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Poland</td>\n",
       "      <td>37846605</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Romania</td>\n",
       "      <td>19237682</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17134873</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>11589616</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Greece</td>\n",
       "      <td>10423056</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>10099270</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>10196707</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>9660350</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>9449321</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Austria</td>\n",
       "      <td>9006400</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>8654618</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>6948445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>6804596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>5792203</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5540718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5421242</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>4937796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>4105268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>3280815</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2722291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>4033963</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>2078932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>1326539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  population  population_in_millions\n",
       "0                  Germany    83783945                      84\n",
       "1           United Kingdom    67886004                      68\n",
       "2                   France    65273512                      65\n",
       "3                    Italy    60461828                      60\n",
       "4                    Spain    46754783                      47\n",
       "5                  Ukraine    43733759                      44\n",
       "6                   Poland    37846605                      38\n",
       "7                  Romania    19237682                      19\n",
       "8              Netherlands    17134873                      17\n",
       "9                  Belgium    11589616                      12\n",
       "10                  Greece    10423056                      10\n",
       "11                  Sweden    10099270                      10\n",
       "12                Portugal    10196707                      10\n",
       "13                 Hungary     9660350                      10\n",
       "14                 Belarus     9449321                       9\n",
       "15                 Austria     9006400                       9\n",
       "16             Switzerland     8654618                       9\n",
       "17                Bulgaria     6948445                       7\n",
       "18                  Serbia     6804596                       7\n",
       "19                 Denmark     5792203                       6\n",
       "20                 Finland     5540718                       6\n",
       "21                  Norway     5421242                       5\n",
       "22                 Ireland     4937796                       5\n",
       "23                 Croatia     4105268                       4\n",
       "24  Bosnia and Herzegovina     3280815                       3\n",
       "25               Lithuania     2722291                       3\n",
       "26                 Moldova     4033963                       4\n",
       "27                Slovenia     2078932                       2\n",
       "28                 Estonia     1326539                       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A dataframe sorted by countries\n",
    "\n",
    "dtypes_countries = np.dtype([\n",
    "          ('country', str),\n",
    "          ('population', int),\n",
    "          ('population_in_millions', int),\n",
    "          ])\n",
    "\n",
    "df_countries = pd.DataFrame(pd.read_csv('Cleaned_dataframes/df_countries.csv', dtype=dtypes_countries))\n",
    "\n",
    "# Show the dataframe\n",
    "df_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe df_days_by_countries\n",
    "\n",
    "- All the days to which there exists traffic and infected data to each country\n",
    "\n",
    "\n",
    "- The length of the dataframe equals 'num_countries' * 'whole_interval_len'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smooth</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>traffic_retail</th>\n",
       "      <th>traffic_supermarket</th>\n",
       "      <th>traffic_parks</th>\n",
       "      <th>traffic_transit_stations</th>\n",
       "      <th>traffic_workplaces</th>\n",
       "      <th>traffic_residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>60.307</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8352 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country       date  new_deaths  new_deaths_smooth  \\\n",
       "0     Germany 2020-02-01           0                  0   \n",
       "1     Germany 2020-02-02           0                  0   \n",
       "2     Germany 2020-02-03           0                  0   \n",
       "3     Germany 2020-02-04           0                  0   \n",
       "4     Germany 2020-02-05           0                  0   \n",
       "...       ...        ...         ...                ...   \n",
       "8347  Estonia 2020-11-10           1                  0   \n",
       "8348  Estonia 2020-11-11           0                  0   \n",
       "8349  Estonia 2020-11-12           0                  0   \n",
       "8350  Estonia 2020-11-13           0                  0   \n",
       "8351  Estonia 2020-11-14           4                  1   \n",
       "\n",
       "      total_deaths_per_million  traffic_retail  traffic_supermarket  \\\n",
       "0                        0.000            1.00                 1.00   \n",
       "1                        0.000            1.00                 1.00   \n",
       "2                        0.000            1.00                 1.00   \n",
       "3                        0.000            1.00                 1.00   \n",
       "4                        0.000            1.00                 1.00   \n",
       "...                        ...             ...                  ...   \n",
       "8347                    57.292            0.96                 1.05   \n",
       "8348                    57.292            0.96                 1.06   \n",
       "8349                    57.292            0.93                 1.03   \n",
       "8350                    57.292            0.90                 1.04   \n",
       "8351                    60.307            0.88                 1.04   \n",
       "\n",
       "      traffic_parks  traffic_transit_stations  traffic_workplaces  \\\n",
       "0              1.00                      1.00                1.00   \n",
       "1              1.00                      1.00                1.00   \n",
       "2              1.00                      1.00                1.00   \n",
       "3              1.00                      1.00                1.00   \n",
       "4              1.00                      1.00                1.00   \n",
       "...             ...                       ...                 ...   \n",
       "8347           1.10                      0.86                0.88   \n",
       "8348           1.06                      0.85                0.88   \n",
       "8349           1.03                      0.81                0.87   \n",
       "8350           0.93                      0.78                0.86   \n",
       "8351           0.96                      0.78                0.92   \n",
       "\n",
       "      traffic_residential  \n",
       "0                    1.00  \n",
       "1                    1.00  \n",
       "2                    1.00  \n",
       "3                    1.00  \n",
       "4                    1.00  \n",
       "...                   ...  \n",
       "8347                 1.04  \n",
       "8348                 1.04  \n",
       "8349                 1.05  \n",
       "8350                 1.05  \n",
       "8351                 1.02  \n",
       "\n",
       "[8352 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A countrywise sorted dataframe s.t. for each day on the time interval of each country there is a row \n",
    "\n",
    "dtypes_days_by_countries = np.dtype([\n",
    "          ('country', str),  # country name\n",
    "          ('date', str), # current date. This will become datetime-time using parse_dates!\n",
    "          ('new_deaths', int), # new deaths on that date\n",
    "          ('new_deaths_smooth', int), # smoothened new deaths on that date\n",
    "          ('total_deaths_per_million', float), # how many deaths per million has occured until that date\n",
    "          ('traffic_retail', float), # retail and recreation traffic on that date\n",
    "          ('traffic_supermarket', float), # supermarket and pharmacy traffic on that date\n",
    "          ('traffic_parks', float),  # park traffic on that date\n",
    "          ('traffic_transit_stations', float), # transit station traffic on that date\n",
    "          ('traffic_workplaces', float), # workplace traffic on that date\n",
    "          ('traffic_residential', float), # residential traffic on that date\n",
    "          ])\n",
    "\n",
    "df_days_by_countries = pd.DataFrame(pd.read_csv('Cleaned_dataframes/df_days_by_countries.csv', dtype=dtypes_days_by_countries))   \n",
    "\n",
    "# Change the date-column from string-type to datetype\n",
    "df_days_by_countries['date'] = pd.to_datetime(df_days_by_countries['date'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# Show the dataframe\n",
    "df_days_by_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting an overview how COVID-19-cases, -deaths and people's traffic behavior developed during the pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Plot all Google's traffic components and also death and infected data countrywise\n",
    "\n",
    "- The vertical black line represents when the tail of the pandemic starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define categories which are plotted\n",
    "traffic_components = ['traffic_retail', 'traffic_supermarket', 'traffic_parks', \n",
    "                      'traffic_transit_stations', 'traffic_workplaces', 'traffic_residential'\n",
    "                     ]\n",
    "\n",
    "description = ['traffic in retail and recreation', 'traffic in supermarkets and pharmacy', 'traffic in parks',\n",
    "               'traffic in transit stations', 'traffic in workplaces', 'traffic in residential ares'\n",
    "              ]\n",
    "\n",
    "\n",
    "# Loop over each country\n",
    "for i in range(num_countries):\n",
    "    \n",
    "    # Define the current country, a temporary dataframe of the country and x-axis (dates)\n",
    "    current_country = european_countries[i]\n",
    "    df_current = df_days_by_countries[(df_days_by_countries['country'] == current_country)]\n",
    "    x = df_current['date'].tolist() \n",
    "    \n",
    "    print('\\033[1m' + current_country)\n",
    "    \n",
    "    # Loop over each traffic component\n",
    "    for j in range(len(traffic_components)):\n",
    "\n",
    "        # Define y-components which are going to be plotted in one figure\n",
    "        y_traffic = df_current[traffic_components[j]].tolist()\n",
    "        y_deaths = df_current['new_deaths'].tolist()\n",
    "\n",
    "        # Define the figure and different y-axis (there are 3 in total: traffic, infected, deaths)\n",
    "        fig, host = plt.subplots(figsize=(26, 6))\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        par1 = host.twinx()\n",
    "\n",
    "        # Set the most right one y-axis to right\n",
    "        par1.spines[\"right\"].set_position((\"axes\", 1.1))\n",
    "\n",
    "        # Plot the traffic, infected and death data\n",
    "        p1, = host.plot(x, y_traffic, \"b-\", label='The change in ' + description[j] +  ' (%)' )\n",
    "        p2, = par1.plot(x, y_deaths, marker = 'o', linestyle='', color = \"black\", label=\"New deaths ()\")\n",
    "\n",
    "        # Define the texts\n",
    "        host.set_ylabel('The change in ' + description[j] +  ' (%)')\n",
    "        par1.set_ylabel(\"New deaths ()\")\n",
    "\n",
    "        # Text on the axis with the correct color\n",
    "        host.yaxis.label.set_color(p1.get_color())\n",
    "        par1.yaxis.label.set_color(p2.get_color())\n",
    "\n",
    "        # Make little spikes for different y-axis\n",
    "        tkw = dict(size=30, width=1.6)\n",
    "        host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "        par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "        host.tick_params(axis='x', **tkw)\n",
    "\n",
    "        plt.axvline(tail_start_date, color='black')\n",
    "        \n",
    "        print('\\033[0m' + description[j])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- Based on previous plots, clearly residential traffic does not impact negatively on the spread of COVID-19. The effect of other traffic components will be analysed more detailed and residential traffic data is not analysed any more in this project.\n",
    " \n",
    "\n",
    "- It is difficult to analyse the impact of different traffic components to the spread of COVID-19 based on the first local maximum of the epidemic (in most countries it happend on March or on April)\n",
    "    \n",
    "    - Almost in every European country all the traffic data components except residential traffic went strongly down at the same time. Therefore, it is difficult to say which traffic component truely mattered based on the beginning of the pandemic.\n",
    "    \n",
    "    \n",
    "- Therefore, let's concentrate the analysis what happend later during the second wave, i.e. concentrate on the tail of the pandemic, autumn which is defined to start on 1.9.2020!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model\n",
    "\n",
    "### Theory behind the model\n",
    "\n",
    "Let's start using SEIR-model. \n",
    "\n",
    "In this extended SEIR-model, the population $N \\in \\mathbb{N}$ is divided in four groups: susceptibles $S(t) \\in \\mathbb{N}$, exposed $E(t) \\in \\mathbb{N}$, infected $I(t) \\in \\mathbb{N}$ and removed $R(t) \\in \\mathbb{N}$. Notice that the group removed $R$ includes everyone who is either recovered from the disease, isolated or died because of it. The changes of these groups can be described by the following equations:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial S}{\\partial t} = - \\frac{\\beta S I }{N}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial t} =  \\frac{\\beta S I}{N} - \\frac{E}{D_e}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial I}{\\partial t} =  \\frac{E}{D_e} - \\frac{I}{D_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial R}{\\partial t} =  \\frac{I}{D_i}\n",
    "\\end{equation}\n",
    "\n",
    "$D_e \\in \\mathbb{R}$ is the latent period of the disease. \n",
    "Furthermore, $D_i \\in \\mathbb{R}$ is the period how long both symptomatic and asymptomatic cases are going to spread the disease before getting noninfectious, dead or isolated from other population. \n",
    "\n",
    "Furthermore, $\\beta(t)$ is the average daily rate how many people the infected $I$ are going to meet inside the population. We fix this rate with Google's traffic components with the equation \n",
    "$\\beta(t) = \\sum_{i \\in \\{1,2,3,4,5\\}} c_i \\tau_{t,i}$.\n",
    "From this equation, the non-fixed parameters $c_1, c_2, c_3, c_4, c_5$ are estimated.\n",
    "\n",
    "\n",
    "The daily death data is assumed to be Poisson distributed. \n",
    "Therefore, the parameters $c_1, c_2, c_3, c_4, c_5$ are estimated with the likelihood function \n",
    "\n",
    "\\begin{equation}\n",
    "L(c_1, c_2, c_3, c_4, c_5) = \\prod_{i=1}^{t} \\frac{e^{- \\lambda_i} \\lambda_i^{x_i}}{x_i !}\n",
    "\\end{equation}\n",
    "\n",
    "In the previous equation $x_i$ is the smoothened deaths at day $i$. Also, $\\lambda_i = \\frac{\\alpha I}{D_i}$ is the rate of the Poisson distribution where $\\alpha \\in [0,1]$ is the proportion of infected who die. It is good to notice $I(t)$ depends on values of $c_1, c_2, c_3, c_4, c_5$. \n",
    "\n",
    "Let's use non-informative priors and MCMC-methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical implementation using STAN\n",
    "#### Add the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cached StanModel\n"
     ]
    }
   ],
   "source": [
    "sm = stan_utils.StanModel_cache(\"./seir_model.stan\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the time points which have a weekly jump\n",
    "\n",
    "- This is the same for different countries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 8, 15, 22, 29, 36, 43, 50, 57, 64, 71]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First define the time points which have a weekly jump\n",
    "t = []\n",
    "for i in range(tail_interval_len):\n",
    "    if (i  % 7 == 0):\n",
    "        t.append(i+1)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prototype: Germany"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "[4, 3, 4, 5, 11, 10, 16, 28, 44, 89, 136]\n",
      "11\n",
      "[1.03, 1.01, 1.0, 0.95, 1.0, 0.94, 0.92, 0.92, 0.89, 0.73, 0.74]\n",
      "11\n",
      "[0.98, 0.96, 0.97, 0.98, 1.06, 1.01, 0.97, 0.98, 1.0, 0.98, 0.98]\n",
      "11\n",
      "[0.86, 0.87, 0.89, 0.88, 0.9, 0.84, 0.77, 0.77, 0.79, 0.73, 0.73]\n",
      "11\n",
      "[0.78, 0.8, 0.84, 0.85, 0.87, 0.84, 0.77, 0.78, 0.85, 0.8200000000000001, 0.84]\n"
     ]
    }
   ],
   "source": [
    "all_fits = []\n",
    "\n",
    "# for current_country in european_countries:\n",
    "for current_country in ['Germany']: # temparately\n",
    "\n",
    "    ###############################################################\n",
    "    # Deaths\n",
    "\n",
    "    deaths_current = df_days_by_countries[(df_days_by_countries['country'] == current_country) &\n",
    "                      (df_days_by_countries['date'] >= tail_start_date)]['new_deaths_smooth'].tolist()\n",
    "\n",
    "    deaths_current = [deaths_current[i] for i in t] \n",
    "\n",
    "    print(len(deaths_current))\n",
    "    print(deaths_current)\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "    # Traffic components\n",
    "\n",
    "    ##############\n",
    "    retail_data_current = df_days_by_countries[(df_days_by_countries['country'] == current_country) &\n",
    "                      (df_days_by_countries['date'] >= tail_start_date)]['traffic_retail'].tolist()\n",
    "    retail_data_current = [retail_data_current[i] for i in t] \n",
    "    print(len(retail_data_current))\n",
    "    print(retail_data_current)\n",
    "\n",
    "\n",
    "    ##############\n",
    "    grocery_data_current = df_days_by_countries[(df_days_by_countries['country'] == current_country) &\n",
    "                      (df_days_by_countries['date'] >= tail_start_date)]['traffic_supermarket'].tolist()\n",
    "    grocery_data_current = [grocery_data_current[i] for i in t] \n",
    "    print(len(grocery_data_current))\n",
    "    print(grocery_data_current)\n",
    "\n",
    "\n",
    "    ##############\n",
    "    transport_data_current = df_days_by_countries[(df_days_by_countries['country'] == current_country) &\n",
    "                      (df_days_by_countries['date'] >= tail_start_date)]['traffic_transit_stations'].tolist()\n",
    "    transport_data_current = [transport_data_current[i] for i in t] \n",
    "    print(len(transport_data_current))\n",
    "    print(transport_data_current)\n",
    "\n",
    "\n",
    "    ##############\n",
    "    workplace_data_current = df_days_by_countries[(df_days_by_countries['country'] == current_country) &\n",
    "                      (df_days_by_countries['date'] >= tail_start_date)]['traffic_workplaces'].tolist()\n",
    "    workplace_data_current = [workplace_data_current[i] for i in t] \n",
    "    print(len(workplace_data_current))\n",
    "    print(workplace_data_current)\n",
    "\n",
    "\n",
    "    ###############################################################\n",
    "\n",
    "    n_days = len(deaths_current)\n",
    "    N = df_countries[(df_countries['country'] == current_country)]['population'][0]\n",
    "\n",
    "    # Some more sophisticated choice for this!\n",
    "    e0 = 100\n",
    "    i0 = 100\n",
    "    r0 = 1000\n",
    "\n",
    "    y0 = [N - e0 - i0 - r0, e0, i0, r0]\n",
    "    t0 = 0\n",
    "    t = t\n",
    "\n",
    "    D_e = 5.3\n",
    "    D_i = 5\n",
    "    alpha = 0.01\n",
    "\n",
    "    deaths = deaths_current\n",
    "    traffic1 = retail_data_current\n",
    "    traffic2 = grocery_data_current\n",
    "    traffic3 = transport_data_current\n",
    "    traffic4 = workplace_data_current\n",
    "\n",
    "    seir_data = {\n",
    "        \"n_days\": n_days,\n",
    "        \"y0\": y0,\n",
    "        \"t0\": t0,\n",
    "        \"ts\": t,\n",
    "        \"N\": N,\n",
    "        \"D_e\": D_e,\n",
    "        \"D_i\": D_i,\n",
    "        \"alpha\": alpha,\n",
    "        \"traffic1\": traffic1,\n",
    "        \"traffic2\": traffic2,\n",
    "        \"traffic3\": traffic3,\n",
    "        \"traffic4\": traffic4,\n",
    "        \"deaths\": deaths\n",
    "    }\n",
    "\n",
    "    all_fits.append(sm.sampling(seir_data))\n",
    "    # samples = fit.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_c5f07aa3e7ff0ad6c30bc396ac1f6086.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "             mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "c[1]         0.58  5.5e-5 3.6e-3   0.57   0.58   0.58   0.58   0.59   4161    1.0\n",
       "c[2]         1.02    0.02   1.01   0.03   0.31   0.72   1.41    3.7   3919    1.0\n",
       "c[3]         0.99    0.02   0.98   0.02   0.28   0.69   1.37   3.68   3792    1.0\n",
       "c[4]         1.02    0.02   1.05   0.02   0.27   0.69   1.42   3.85   3895    1.0\n",
       "y[1,1]      8.4e7  5.8e-3   0.38  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4161    1.0\n",
       "y[2,1]      8.4e7     0.1    6.5  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4161    1.0\n",
       "y[3,1]      8.4e7    0.39  25.01  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4162    1.0\n",
       "y[4,1]      8.4e7    1.12  72.09  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4164    1.0\n",
       "y[5,1]      8.4e7    2.86 184.55  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4166    1.0\n",
       "y[6,1]      8.4e7    6.83 441.11  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4167    1.0\n",
       "y[7,1]      8.4e7   15.62 1008.5  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4168    1.0\n",
       "y[8,1]      8.4e7   34.62 2235.1  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4169    1.0\n",
       "y[9,1]      8.4e7   74.95 4840.1  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4170    1.0\n",
       "y[10,1]     8.4e7  159.35  1.0e4  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   4171    1.0\n",
       "y[11,1]     8.3e7  333.52  2.2e4  8.3e7  8.3e7  8.3e7  8.3e7  8.3e7   4171    1.0\n",
       "y[1,2]     137.68  5.3e-3   0.34  137.0 137.45 137.69 137.92 138.35   4161    1.0\n",
       "y[2,2]     399.71    0.06   4.01 391.71 397.01 399.87 402.41 407.54   4162    1.0\n",
       "y[3,2]     756.98    0.19  12.36  732.6 748.56 757.37  765.3 781.17   4163    1.0\n",
       "y[4,2]     1422.0     0.5  31.97 1359.3 1400.2 1423.0 1443.6 1484.9   4165    1.0\n",
       "y[5,2]     2678.6    1.19  76.63 2528.9 2626.2 2680.6 2730.3 2830.0   4166    1.0\n",
       "y[6,2]     5045.6    2.71 175.25 4704.8 4925.5 5049.4 5163.8 5393.4   4168    1.0\n",
       "y[7,2]     9503.2    6.01 388.23 8751.8 9236.7 9510.2 9764.5  1.0e4   4169    1.0\n",
       "y[8,2]      1.8e4   13.01 840.31  1.6e4  1.7e4  1.8e4  1.8e4  2.0e4   4170    1.0\n",
       "y[9,2]      3.4e4   27.66 1786.3  3.0e4  3.2e4  3.4e4  3.5e4  3.7e4   4171    1.0\n",
       "y[10,2]     6.3e4   57.92 3740.8  5.6e4  6.1e4  6.3e4  6.6e4  7.1e4   4171    1.0\n",
       "y[11,2]     1.2e5  119.61 7725.3  1.0e5  1.1e5  1.2e5  1.2e5  1.3e5   4172    1.0\n",
       "y[1,3]     102.38  4.8e-4   0.03 102.32 102.36 102.38  102.4 102.44   4161    1.0\n",
       "y[2,3]      231.1    0.03   1.62 227.86  230.0 231.16 232.19 234.26   4159    1.0\n",
       "y[3,3]     488.97     0.1   6.53 476.04 484.52 489.18 493.36 501.73   4162    1.0\n",
       "y[4,3]     923.66    0.28  17.98 888.29 911.41 924.19 935.78 958.95   4164    1.0\n",
       "y[5,3]     1740.0    0.69  44.53 1652.8 1709.5 1741.2 1770.0 1827.8   4166    1.0\n",
       "y[6,3]     3277.6    1.61 103.97 3075.0 3206.4 3280.0 3347.7 3483.5   4167    1.0\n",
       "y[7,3]     6173.5    3.62 233.62 5720.4 6013.3 6178.1 6330.9 6638.3   4168    1.0\n",
       "y[8,3]      1.2e4    7.91 511.03  1.1e4  1.1e4  1.2e4  1.2e4  1.3e4   4169    1.0\n",
       "y[9,3]      2.2e4   16.96 1095.4  2.0e4  2.1e4  2.2e4  2.3e4  2.4e4   4170    1.0\n",
       "y[10,3]     4.1e4   35.77 2310.0  3.7e4  4.0e4  4.1e4  4.3e4  4.6e4   4171    1.0\n",
       "y[11,3]     7.7e4   74.35 4802.0  6.8e4  7.4e4  7.7e4  8.1e4  8.7e4   4172    1.0\n",
       "y[1,4]     1020.1  3.3e-5 2.1e-3 1020.1 1020.1 1020.1 1020.1 1020.1   4161    1.0\n",
       "y[2,4]     1235.1    0.01   0.86 1233.4 1234.5 1235.1 1235.7 1236.8   4157    1.0\n",
       "y[3,4]     1728.7    0.09   6.13 1716.6 1724.6 1728.9 1732.8 1740.7   4161    1.0\n",
       "y[4,4]     2686.2    0.34  22.14 2642.5 2671.1 2686.9 2701.1 2729.5   4163    1.0\n",
       "y[5,4]     4490.9    0.98  63.38 4366.2 4447.7 4492.7 4533.6 4615.4   4164    1.0\n",
       "y[6,4]     7890.4    2.51 161.89 7573.4 7779.8 7894.8 7999.6 8209.6   4166    1.0\n",
       "y[7,4]      1.4e4    5.99 386.67  1.4e4  1.4e4  1.4e4  1.5e4  1.5e4   4167    1.0\n",
       "y[8,4]      2.6e4   13.69 883.79  2.5e4  2.6e4  2.6e4  2.7e4  2.8e4   4168    1.0\n",
       "y[9,4]      4.9e4   30.33 1958.3  4.5e4  4.8e4  4.9e4  5.0e4  5.3e4   4169    1.0\n",
       "y[10,4]     9.2e4   65.66 4240.2  8.4e4  8.9e4  9.2e4  9.5e4  1.0e5   4170    1.0\n",
       "y[11,4]     1.7e5  139.56 9013.2  1.5e5  1.7e5  1.7e5  1.8e5  1.9e5   4171    1.0\n",
       "beta[1]       0.6  5.7e-5 3.7e-3   0.59    0.6    0.6    0.6   0.61   4161    1.0\n",
       "beta[2]      0.59  5.6e-5 3.6e-3   0.58   0.58   0.59   0.59   0.59   4161    1.0\n",
       "beta[3]      0.58  5.5e-5 3.6e-3   0.57   0.58   0.58   0.58   0.59   4161    1.0\n",
       "beta[4]      0.55  5.3e-5 3.4e-3   0.54   0.55   0.55   0.55   0.56   4161    1.0\n",
       "beta[5]      0.58  5.5e-5 3.6e-3   0.57   0.58   0.58   0.58   0.59   4161    1.0\n",
       "beta[6]      0.55  5.2e-5 3.4e-3   0.54   0.54   0.55   0.55   0.55   4161    1.0\n",
       "beta[7]      0.53  5.1e-5 3.3e-3   0.53   0.53   0.53   0.54   0.54   4161    1.0\n",
       "beta[8]      0.53  5.1e-5 3.3e-3   0.53   0.53   0.53   0.54   0.54   4161    1.0\n",
       "beta[9]      0.52  4.9e-5 3.2e-3   0.51   0.51   0.52   0.52   0.52   4161    1.0\n",
       "beta[10]     0.42  4.0e-5 2.6e-3   0.42   0.42   0.42   0.43   0.43   4161    1.0\n",
       "beta[11]     0.43  4.1e-5 2.6e-3   0.42   0.43   0.43   0.43   0.43   4161    1.0\n",
       "lambda[1]     0.2  9.6e-7 6.2e-5    0.2    0.2    0.2    0.2    0.2   4161    1.0\n",
       "lambda[2]    0.46  5.0e-5 3.2e-3   0.46   0.46   0.46   0.46   0.47   4159    1.0\n",
       "lambda[3]    0.98  2.0e-4   0.01   0.95   0.97   0.98   0.99    1.0   4162    1.0\n",
       "lambda[4]    1.85  5.6e-4   0.04   1.78   1.82   1.85   1.87   1.92   4164    1.0\n",
       "lambda[5]    3.48  1.4e-3   0.09   3.31   3.42   3.48   3.54   3.66   4166    1.0\n",
       "lambda[6]    6.56  3.2e-3   0.21   6.15   6.41   6.56    6.7   6.97   4167    1.0\n",
       "lambda[7]   12.35  7.2e-3   0.47  11.44  12.03  12.36  12.66  13.28   4168    1.0\n",
       "lambda[8]   23.25    0.02   1.02  21.28  22.55  23.27  23.94  25.29   4169    1.0\n",
       "lambda[9]   43.78    0.03   2.19  39.57  42.27   43.8  45.25  48.17   4170    1.0\n",
       "lambda[10]  82.36    0.07   4.62  73.52  79.17   82.4  85.45  91.67   4171    1.0\n",
       "lambda[11] 154.75    0.15    9.6 136.46 148.11 154.81 161.17 174.18   4172    1.0\n",
       "lp__       1063.3    0.05   1.61 1059.3 1062.5 1063.6 1064.4 1065.3   1101    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Wed Nov 25 08:44:11 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_fits[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The findings of this research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An analysis of potential mistakes\n",
    "\n",
    "- Different traffic components correlate with another which adds noise\n",
    "    - Example: A person uses public transport, goes to the supermarket, goes to a park and travels back home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion \n",
    "\n",
    "- The results which traffic components have the biggest impact on the spread of COVID-19 are intuitive: \n",
    "    - In places like supermarkets and pharmacies people can hold distance with other people relatively well.\n",
    "    - On contrary, in public transports people easily go very close to other people.\n",
    "    - etc...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Good articles\n",
    "\n",
    "- https://www.medrxiv.org/content/10.1101/2020.03.03.20030593v1.supplementary-material\n",
    "    - This has a great supplementary material section, and our model is based on that\n",
    "\n",
    "- https://www.fhi.no/en/id/infectious-diseases/coronavirus/coronavirus-modelling-at-the-niph-fhi/\n",
    "    - The Norwegian Institute of Public Health has a great report of modeling COVID-19 with extended SEIR-model \n",
    "\n",
    "- https://www.medrxiv.org/content/10.1101/2020.05.28.20116129v3.full.pdf\n",
    "    - More like nice to read to get some ideas, not direct connection to our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
