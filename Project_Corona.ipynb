{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understanding the spread of COVID-19 based on European traffic data during summer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Data\n",
    "\n",
    "- Our World in Data COVID-19 dataset\n",
    "    - Data on deaths in different countries.\n",
    "\n",
    "\n",
    "- Google's traffic data \n",
    "    - Google provides anonymized insights from products such as Google Maps for researchers to help them to make critical analysis to combat COVID-19. \n",
    "    - Google has divided their traffic data into six traffic components: \n",
    "        1. retail \\& recreation\n",
    "            - places like restaurants, cafes, shopping centers, theme parks, museums, libraries and movie theaters\n",
    "        2. grocery \\& pharmacy\n",
    "            - places like grocery markets, food warehouses, farmers markets, specialty food shops, drug stores and pharmacies\n",
    "        3. parks\n",
    "            - places like national parks, public beaches, marinas, dog parks, plazas and public gardens\n",
    "        4. transit stations\n",
    "            - places like public transport hubs such as subway, bus and train stations\n",
    "        5. workplaces \n",
    "            - places of work\n",
    "        6. residential \n",
    "            -  places of residence\n",
    "     \n",
    "  - These components do not tell anything how much time people spend in each section on average but they still give a lot of information how people's traffic behavior changed during the pandemic\n",
    " \n",
    " - The traffic data's baseline is counted as a median value of multiple days. Day-to-day changes should not be emphasized too much because they are effected on many different factors, f.e. the weather and public events.  \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.2. Moral behind the Bayesian model\n",
    "\n",
    "\n",
    "- Getting the traffic data down slows down the spread of the virus. \n",
    "    - Several articles (Ferretti et al 2020, ECDC report, LSHTM report) have pointed out pre-symptomatic and asymptomatic  infections  play  a  significant  role  in  the  spread  of  COVID-19.  Indeed,  this observation  is  an  argument  it  may  not  be  enough  to  get  the  symptomatic  cases  to  stay at  home. Also  governmental  restrictions  should  be  implemented  to  get people’s movement down and furthermore the pandemic under control.\n",
    "    - Essentially, the reason to implement non-pharmaceutical interventions is to get people's traffic data down!\n",
    "\n",
    "\n",
    "- There are multiple reasons why it makes sense to analyse European countries in this research\n",
    "    - COVID-19 hit European countries badly during autumn\n",
    "    - European governments have similar capabilities to restrict their citizens movement in comparison to many countries, f.e. China\n",
    "    - European countries adapted suppression strategy instead of mitigation one\n",
    "    \n",
    "    \n",
    "- There are many major differences between European countries which effect on the spread of COVID-19\n",
    "    - Examples: different age distributions, different population densities in cities, cultural differences\n",
    "    - Therefore comparisons between European countries should be avoided\n",
    "\n",
    "    \n",
    "- The COVID-19-case data is not reliable at least as the only measure about the development of the epidemic. COVID-19-death data has many benefits compared to the COVID-19 case data! \n",
    "    - The amount of testing varies a lot between countries\n",
    "    - Also using death data over infected data has the benefit that deaths measures much better country's success against the epidemic than infections\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1.3. Motivation, research goals\n",
    "\n",
    "\n",
    "1. To create a model which predicts the spread of the epidemic well based on the traffic data and data on deaths.\n",
    "\n",
    "2. Based on the created model, trying to understand which of these Google's traffic components predicted the spread of COVID-19 in different European countries\n",
    "\n",
    "\n",
    "### 1.4.  Structure\n",
    "\n",
    "\n",
    "\n",
    "1. Introduction\n",
    "    - Describes the essentials of this notebook\n",
    "2. Getting an overview how COVID-19-cases and people's traffic behavior developed during the pandemic\n",
    "    - This section gives moral for sections 4-8.\n",
    "3. Dividing regions inside European countries in groups based on the development of the epidemic\n",
    "    - COVID-19 hit European countries very differently. Therefore they are divided in three different groups.\n",
    "4. Based on countries which did well against the epidemic during summer, understanding the impact of different traffic components to the spread of the epidemic\n",
    "    - This section uses the assumption: The spread of COVID-19 can be predicted with people's traffic behavior.\n",
    "    - This section gives understanding which Google traffic components had the biggest impact on the spread of COVID-19.\n",
    "    - Important section, contains results!\n",
    "5. Based on countries where the epidemic escalated during the summer, understanding the impact of different traffic components to the spread of the epidemic\n",
    "    - This section has the same aim as the section 5 has. However, the methods used in these sections strongly differ from each other \n",
    "    - Important section, contains results!\n",
    "6. Getting an overview if the traffic components with the most impact predicted well the spread of COVID-19 in different European countries\n",
    "    - NOT YET IMPLEMENTED AT ALL\n",
    "7. Summary\n",
    "    - NOT YET IMPLEMENTED AT ALL\n",
    "    - Summaries the whole notebook and also opens discussion about the findings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5. Libraries used in this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn import linear_model\n",
    "\n",
    "import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "import pystan\n",
    "from scipy.integrate import odeint\n",
    "\n",
    "import stan_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6. Parameters which need to be defined manually\n",
    "\n",
    "- All the parameters, which need to be defined manually, are here\n",
    "\n",
    "\n",
    "- During text there are detailed explanations what these parameters are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################################################################\n",
    "\n",
    "# There is COVID-19-data from February until now\n",
    "observations_start_date = datetime.datetime(2020, 2, 1, 0, 0)\n",
    "observations_end_date = datetime.datetime(2020, 11, 15, 0, 0)\n",
    "\n",
    "# However, the data analysis of this notebook concentrates on autumn months, i.e. on so called tail\n",
    "tail_start_date = datetime.datetime(2020, 9, 1, 0, 0)\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# European countries ordered by population\n",
    "european_countries = [\n",
    "    'Germany', 'United Kingdom', 'France', 'Italy', 'Spain', \n",
    "    'Ukraine', 'Poland', 'Romania','Netherlands', 'Belgium', \n",
    "    'Greece', 'Sweden', 'Portugal', 'Hungary', 'Belarus', \n",
    "    'Austria', 'Switzerland', 'Bulgaria', 'Serbia', 'Denmark', \n",
    "    'Finland', 'Norway', 'Ireland', 'Croatia', 'Moldova', \n",
    "    'Bosnia and Herzegovina', 'Lithuania', 'Slovenia', 'Estonia' ]\n",
    "\n",
    "\n",
    "#############################################################################\n",
    "\n",
    "# Window size for convolution\n",
    "w = 7\n",
    "\n",
    "# Death limit\n",
    "d = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 European countries analysed in this notebook.\n",
      "The length of the whole interval: 288\n",
      "The length of the tail interval: 75\n"
     ]
    }
   ],
   "source": [
    "# Follows directly from manual definitions \n",
    "num_countries = len(european_countries)\n",
    "whole_interval_len = (observations_end_date - observations_start_date).days \n",
    "tail_interval_len = (observations_end_date - tail_start_date).days \n",
    "date_list = [observations_start_date + datetime.timedelta(days=x) for x in range(whole_interval_len)]\n",
    "\n",
    "print(\"There are \" + str(num_countries) + \" European countries analysed in this notebook.\")\n",
    "print(\"The length of the whole interval: \" + str(whole_interval_len))\n",
    "print(\"The length of the tail interval: \" + str(tail_interval_len))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definition: Autumn interval $\\tau_{\\text{autumn}}$\n",
    "\n",
    "Let's denote the autumn interval with $\\tau_{\\text{autumn}} = \\{ 0,1,2, \\dots, 75 \\}$. Indeed $t = 0$ corresponds the date 1.9.2020, $t = 1$ corresponds the date 2.9.2020 and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.7. Adding previously cleaned data to dataframes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe df_countries\n",
    "\n",
    "- The length of this dataframe is 'num_countries'. Indeed, for each country there is one row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>population</th>\n",
       "      <th>population_in_millions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>83783945</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>67886004</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>France</td>\n",
       "      <td>65273512</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Italy</td>\n",
       "      <td>60461828</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spain</td>\n",
       "      <td>46754783</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ukraine</td>\n",
       "      <td>43733759</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Poland</td>\n",
       "      <td>37846605</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Romania</td>\n",
       "      <td>19237682</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Netherlands</td>\n",
       "      <td>17134873</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Belgium</td>\n",
       "      <td>11589616</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Greece</td>\n",
       "      <td>10423056</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Sweden</td>\n",
       "      <td>10099270</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Portugal</td>\n",
       "      <td>10196707</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Hungary</td>\n",
       "      <td>9660350</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Belarus</td>\n",
       "      <td>9449321</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Austria</td>\n",
       "      <td>9006400</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Switzerland</td>\n",
       "      <td>8654618</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bulgaria</td>\n",
       "      <td>6948445</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Serbia</td>\n",
       "      <td>6804596</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Denmark</td>\n",
       "      <td>5792203</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Finland</td>\n",
       "      <td>5540718</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Norway</td>\n",
       "      <td>5421242</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>4937796</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Croatia</td>\n",
       "      <td>4105268</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Bosnia and Herzegovina</td>\n",
       "      <td>3280815</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Lithuania</td>\n",
       "      <td>2722291</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Moldova</td>\n",
       "      <td>4033963</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Slovenia</td>\n",
       "      <td>2078932</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>1326539</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   country  population  population_in_millions\n",
       "0                  Germany    83783945                      84\n",
       "1           United Kingdom    67886004                      68\n",
       "2                   France    65273512                      65\n",
       "3                    Italy    60461828                      60\n",
       "4                    Spain    46754783                      47\n",
       "5                  Ukraine    43733759                      44\n",
       "6                   Poland    37846605                      38\n",
       "7                  Romania    19237682                      19\n",
       "8              Netherlands    17134873                      17\n",
       "9                  Belgium    11589616                      12\n",
       "10                  Greece    10423056                      10\n",
       "11                  Sweden    10099270                      10\n",
       "12                Portugal    10196707                      10\n",
       "13                 Hungary     9660350                      10\n",
       "14                 Belarus     9449321                       9\n",
       "15                 Austria     9006400                       9\n",
       "16             Switzerland     8654618                       9\n",
       "17                Bulgaria     6948445                       7\n",
       "18                  Serbia     6804596                       7\n",
       "19                 Denmark     5792203                       6\n",
       "20                 Finland     5540718                       6\n",
       "21                  Norway     5421242                       5\n",
       "22                 Ireland     4937796                       5\n",
       "23                 Croatia     4105268                       4\n",
       "24  Bosnia and Herzegovina     3280815                       3\n",
       "25               Lithuania     2722291                       3\n",
       "26                 Moldova     4033963                       4\n",
       "27                Slovenia     2078932                       2\n",
       "28                 Estonia     1326539                       1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A dataframe sorted by countries\n",
    "\n",
    "dtypes_countries = np.dtype([\n",
    "          ('country', str),\n",
    "          ('population', int),\n",
    "          ('population_in_millions', int),\n",
    "          ])\n",
    "\n",
    "df_countries = pd.DataFrame(pd.read_csv('Cleaned_dataframes/df_countries.csv', dtype=dtypes_countries))\n",
    "\n",
    "# Show the dataframe\n",
    "df_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataframe df_days_by_countries\n",
    "\n",
    "- All the days to which there exists traffic and infected data to each country\n",
    "\n",
    "\n",
    "- The length of the dataframe equals 'num_countries' * 'whole_interval_len'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>date</th>\n",
       "      <th>new_deaths</th>\n",
       "      <th>new_deaths_smooth</th>\n",
       "      <th>total_deaths_per_million</th>\n",
       "      <th>traffic_retail</th>\n",
       "      <th>traffic_supermarket</th>\n",
       "      <th>traffic_parks</th>\n",
       "      <th>traffic_transit_stations</th>\n",
       "      <th>traffic_workplaces</th>\n",
       "      <th>traffic_residential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-02</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-03</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-04</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>2020-02-05</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8347</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-10</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.05</td>\n",
       "      <td>1.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8348</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.96</td>\n",
       "      <td>1.06</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8349</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.03</td>\n",
       "      <td>1.03</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.87</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8350</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>57.292</td>\n",
       "      <td>0.90</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.86</td>\n",
       "      <td>1.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8351</th>\n",
       "      <td>Estonia</td>\n",
       "      <td>2020-11-14</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>60.307</td>\n",
       "      <td>0.88</td>\n",
       "      <td>1.04</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.92</td>\n",
       "      <td>1.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8352 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      country       date  new_deaths  new_deaths_smooth  \\\n",
       "0     Germany 2020-02-01           0                  0   \n",
       "1     Germany 2020-02-02           0                  0   \n",
       "2     Germany 2020-02-03           0                  0   \n",
       "3     Germany 2020-02-04           0                  0   \n",
       "4     Germany 2020-02-05           0                  0   \n",
       "...       ...        ...         ...                ...   \n",
       "8347  Estonia 2020-11-10           1                  0   \n",
       "8348  Estonia 2020-11-11           0                  0   \n",
       "8349  Estonia 2020-11-12           0                  0   \n",
       "8350  Estonia 2020-11-13           0                  0   \n",
       "8351  Estonia 2020-11-14           4                  1   \n",
       "\n",
       "      total_deaths_per_million  traffic_retail  traffic_supermarket  \\\n",
       "0                        0.000            1.00                 1.00   \n",
       "1                        0.000            1.00                 1.00   \n",
       "2                        0.000            1.00                 1.00   \n",
       "3                        0.000            1.00                 1.00   \n",
       "4                        0.000            1.00                 1.00   \n",
       "...                        ...             ...                  ...   \n",
       "8347                    57.292            0.96                 1.05   \n",
       "8348                    57.292            0.96                 1.06   \n",
       "8349                    57.292            0.93                 1.03   \n",
       "8350                    57.292            0.90                 1.04   \n",
       "8351                    60.307            0.88                 1.04   \n",
       "\n",
       "      traffic_parks  traffic_transit_stations  traffic_workplaces  \\\n",
       "0              1.00                      1.00                1.00   \n",
       "1              1.00                      1.00                1.00   \n",
       "2              1.00                      1.00                1.00   \n",
       "3              1.00                      1.00                1.00   \n",
       "4              1.00                      1.00                1.00   \n",
       "...             ...                       ...                 ...   \n",
       "8347           1.10                      0.86                0.88   \n",
       "8348           1.06                      0.85                0.88   \n",
       "8349           1.03                      0.81                0.87   \n",
       "8350           0.93                      0.78                0.86   \n",
       "8351           0.96                      0.78                0.92   \n",
       "\n",
       "      traffic_residential  \n",
       "0                    1.00  \n",
       "1                    1.00  \n",
       "2                    1.00  \n",
       "3                    1.00  \n",
       "4                    1.00  \n",
       "...                   ...  \n",
       "8347                 1.04  \n",
       "8348                 1.04  \n",
       "8349                 1.05  \n",
       "8350                 1.05  \n",
       "8351                 1.02  \n",
       "\n",
       "[8352 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A countrywise sorted dataframe s.t. for each day on the time interval of each country there is a row \n",
    "\n",
    "dtypes_days_by_countries = np.dtype([\n",
    "          ('country', str),  # country name\n",
    "          ('date', str), # current date. This will become datetime-time using parse_dates!\n",
    "          ('new_deaths', int), # new deaths on that date\n",
    "          ('new_deaths_smooth', int), # smoothened new deaths on that date\n",
    "          ('total_deaths_per_million', float), # how many deaths per million has occured until that date\n",
    "          ('traffic_retail', float), # retail and recreation traffic on that date\n",
    "          ('traffic_supermarket', float), # supermarket and pharmacy traffic on that date\n",
    "          ('traffic_parks', float),  # park traffic on that date\n",
    "          ('traffic_transit_stations', float), # transit station traffic on that date\n",
    "          ('traffic_workplaces', float), # workplace traffic on that date\n",
    "          ('traffic_residential', float), # residential traffic on that date\n",
    "          ])\n",
    "\n",
    "df_days_by_countries = pd.DataFrame(pd.read_csv('Cleaned_dataframes/df_days_by_countries.csv', dtype=dtypes_days_by_countries))   \n",
    "\n",
    "# Change the date-column from string-type to datetype\n",
    "df_days_by_countries['date'] = pd.to_datetime(df_days_by_countries['date'], format='%Y-%m-%d')\n",
    "\n",
    "\n",
    "#pd.set_option('display.max_rows', None)\n",
    "# Show the dataframe\n",
    "df_days_by_countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Getting an overview how COVID-19-cases, -deaths and people's traffic behavior developed during the pandemic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. Plot all Google's traffic components and also death and infected data countrywise\n",
    "\n",
    "- The vertical black line represents when the tail of the pandemic starts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define categories which are plotted\n",
    "traffic_components = ['traffic_retail', 'traffic_supermarket', 'traffic_parks', \n",
    "                      'traffic_transit_stations', 'traffic_workplaces', 'traffic_residential'\n",
    "                     ]\n",
    "\n",
    "description = ['traffic in retail and recreation', 'traffic in supermarkets and pharmacy', 'traffic in parks',\n",
    "               'traffic in transit stations', 'traffic in workplaces', 'traffic in residential ares'\n",
    "              ]\n",
    "\n",
    "\n",
    "# Loop over each country\n",
    "for i in range(num_countries):\n",
    "    \n",
    "    # Define the current country, a temporary dataframe of the country and x-axis (dates)\n",
    "    current_country = european_countries[i]\n",
    "    df_current = df_days_by_countries[(df_days_by_countries['country'] == current_country)]\n",
    "    x = df_current['date'].tolist() \n",
    "    \n",
    "    print('\\033[1m' + current_country)\n",
    "    \n",
    "    # Loop over each traffic component\n",
    "    for j in range(len(traffic_components)):\n",
    "\n",
    "        # Define y-components which are going to be plotted in one figure\n",
    "        y_traffic = df_current[traffic_components[j]].tolist()\n",
    "        y_deaths = df_current['new_deaths'].tolist()\n",
    "\n",
    "        # Define the figure and different y-axis (there are 3 in total: traffic, infected, deaths)\n",
    "        fig, host = plt.subplots(figsize=(26, 6))\n",
    "        fig.subplots_adjust(right=0.75)\n",
    "        par1 = host.twinx()\n",
    "\n",
    "        # Set the most right one y-axis to right\n",
    "        par1.spines[\"right\"].set_position((\"axes\", 1.1))\n",
    "\n",
    "        # Plot the traffic, infected and death data\n",
    "        p1, = host.plot(x, y_traffic, \"b-\", label='The change in ' + description[j] +  ' (%)' )\n",
    "        p2, = par1.plot(x, y_deaths, marker = 'o', linestyle='', color = \"black\", label=\"New deaths ()\")\n",
    "\n",
    "        # Define the texts\n",
    "        host.set_ylabel('The change in ' + description[j] +  ' (%)')\n",
    "        par1.set_ylabel(\"New deaths ()\")\n",
    "\n",
    "        # Text on the axis with the correct color\n",
    "        host.yaxis.label.set_color(p1.get_color())\n",
    "        par1.yaxis.label.set_color(p2.get_color())\n",
    "\n",
    "        # Make little spikes for different y-axis\n",
    "        tkw = dict(size=30, width=1.6)\n",
    "        host.tick_params(axis='y', colors=p1.get_color(), **tkw)\n",
    "        par1.tick_params(axis='y', colors=p2.get_color(), **tkw)\n",
    "        host.tick_params(axis='x', **tkw)\n",
    "\n",
    "        plt.axvline(tail_start_date, color='black')\n",
    "        \n",
    "        print('\\033[0m' + description[j])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusions\n",
    "\n",
    "- Based on previous plots, clearly residential traffic does not impact negatively on the spread of COVID-19. The effect of other traffic components will be analysed more detailed and residential traffic data is not analysed any more in this project.\n",
    " \n",
    "\n",
    "- It is difficult to analyse the impact of different traffic components to the spread of COVID-19 based on the first local maximum of the epidemic (in most countries it happend on March or on April)\n",
    "    \n",
    "    - Almost in every European country all the traffic data components except residential traffic went strongly down at the same time. Therefore, it is difficult to say which traffic component truely mattered based on the beginning of the pandemic.\n",
    "    \n",
    "    \n",
    "- Therefore, let's concentrate the analysis what happend later during the second wave, i.e. concentrate on the tail of the pandemic, autumn which is defined to start on 1.9.2020!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayesian model\n",
    "\n",
    "### Theory behind the model\n",
    "\n",
    "Let's start using SEIR-model. \n",
    "\n",
    "In this extended SEIR-model, the population $N \\in \\mathbb{N}$ is divided in four groups: susceptibles $S(t) \\in \\mathbb{N}$, exposed $E(t) \\in \\mathbb{N}$, infected $I(t) \\in \\mathbb{N}$ and removed $R(t) \\in \\mathbb{N}$. Notice that the group removed $R$ includes everyone who is either recovered from the disease, isolated or died because of it. The changes of these groups can be described by the following equations:\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial S}{\\partial t} = - \\frac{\\beta S I }{N}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial E}{\\partial t} =  \\frac{\\beta S I}{N} - \\frac{E}{D_e}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial I}{\\partial t} =  \\frac{E}{D_e} - \\frac{I}{D_i}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{\\partial R}{\\partial t} =  \\frac{I}{D_i}\n",
    "\\end{equation}\n",
    "\n",
    "$D_e \\in \\mathbb{R}$ is the latent period of the disease. \n",
    "Furthermore, $D_i \\in \\mathbb{R}$ is the period how long both symptomatic and asymptomatic cases are going to spread the disease before getting noninfectious, dead or isolated from other population. \n",
    "\n",
    "Furthermore, $\\beta(t)$ is the average daily rate how many people the infected $I$ are going to meet inside the population. We fix this rate with Google's traffic components with the equation \n",
    "$\\beta(t) = \\sum_{i \\in \\{1,2,3,4,5\\}} c_i \\tau_{t,i}$.\n",
    "From this equation, the non-fixed parameters $c_1, c_2, c_3, c_4, c_5$ are estimated.\n",
    "\n",
    "\n",
    "The daily death data is assumed to be Poisson distributed. \n",
    "Therefore, the parameters $c_1, c_2, c_3, c_4, c_5$ are estimated with the likelihood function \n",
    "\n",
    "\\begin{equation}\n",
    "L(c_1, c_2, c_3, c_4, c_5) = \\prod_{i=1}^{t} \\frac{e^{- \\lambda_i} \\lambda_i^{x_i}}{x_i !}\n",
    "\\end{equation}\n",
    "\n",
    "In the previous equation $x_i$ is the smoothened deaths at day $i$. Also, $\\lambda_i = \\frac{\\alpha I}{D_i}$ is the rate of the Poisson distribution where $\\alpha \\in [0,1]$ is the proportion of infected who die. It is good to notice $I(t)$ depends on values of $c_1, c_2, c_3, c_4, c_5$. \n",
    "\n",
    "Let's use non-informative priors and MCMC-methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Practical implementation using STAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 14, 21, 28, 35, 42, 49, 56, 63, 70]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = []\n",
    "for i in range(tail_interval_len):\n",
    "    if ((i + 1) % 7 == 0):\n",
    "        t.append(i+1)\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[3, 4, 4, 10, 10, 12, 28, 37, 80, 120]\n"
     ]
    }
   ],
   "source": [
    "deaths_germany = df_days_by_countries[(df_days_by_countries['country'] == 'Germany') &\n",
    "                  (df_days_by_countries['date'] >= tail_start_date)]['new_deaths_smooth'].tolist()\n",
    "\n",
    "deaths_germany = [deaths_germany[i] for i in t] \n",
    "\n",
    "print(len(deaths_germany))\n",
    "print(deaths_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[1.0, 0.99, 0.96, 0.92, 0.93, 0.94, 0.89, 0.86, 0.73, 0.73]\n",
      "10\n",
      "[0.88, 0.9, 0.89, 0.76, 0.86, 0.8, 0.74, 0.8, 0.74, 0.74]\n"
     ]
    }
   ],
   "source": [
    "retail_data_germany = df_days_by_countries[(df_days_by_countries['country'] == 'Germany') &\n",
    "                  (df_days_by_countries['date'] >= tail_start_date)]['traffic_retail'].tolist()\n",
    "retail_data_germany = [retail_data_germany[i] for i in t] \n",
    "print(len(retail_data_germany))\n",
    "print(retail_data_germany)\n",
    "\n",
    "transport_data_germany = df_days_by_countries[(df_days_by_countries['country'] == 'Germany') &\n",
    "                  (df_days_by_countries['date'] >= tail_start_date)]['traffic_transit_stations'].tolist()\n",
    "transport_data_germany = [transport_data_germany[i] for i in t] \n",
    "print(len(transport_data_germany))\n",
    "print(transport_data_germany)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:pystan:COMPILING THE C++ CODE FOR MODEL anon_model_1fd928b1c3f5d28e7940494b27230ea4 NOW.\n"
     ]
    }
   ],
   "source": [
    "sm = stan_utils.StanModel_cache(\"./seir_model.stan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pystan:517 of 4000 iterations saturated the maximum tree depth of 10 (12.9 %)\n",
      "WARNING:pystan:Run again with max_treedepth larger than 10 to avoid saturation\n"
     ]
    }
   ],
   "source": [
    "n_days = len(deaths_germany)\n",
    "N = df_countries[(df_countries['country'] == 'Germany')]['population'][0]\n",
    "\n",
    "e0 = 100\n",
    "i0 = 100\n",
    "r0 = 1000\n",
    "\n",
    "y0 = [N - e0 - i0 - r0, e0, i0, r0]\n",
    "t0 = 0\n",
    "t = t\n",
    "\n",
    "D_e = 5.3\n",
    "D_i = 5\n",
    "alpha = 0.01\n",
    "\n",
    "traffic1 = retail_data_germany\n",
    "traffic2 = transport_data_germany\n",
    "deaths = deaths_germany\n",
    "\n",
    "seir_data = {\n",
    "    \"n_days\": n_days,\n",
    "    \"y0\": y0,\n",
    "    \"t0\": t0,\n",
    "    \"ts\": t,\n",
    "    \"N\": N,\n",
    "    \"D_e\": D_e,\n",
    "    \"D_i\": D_i,\n",
    "    \"alpha\": alpha,\n",
    "    \"traffic1\": traffic1,\n",
    "    \"traffic2\": traffic2,\n",
    "    \"deaths\": deaths\n",
    "}\n",
    "\n",
    "fit = sm.sampling(seir_data)\n",
    "samples = fit.extract(permuted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Inference for Stan model: anon_model_1fd928b1c3f5d28e7940494b27230ea4.\n",
       "4 chains, each with iter=2000; warmup=1000; thin=1; \n",
       "post-warmup draws per chain=1000, total post-warmup draws=4000.\n",
       "\n",
       "             mean se_mean     sd   2.5%    25%    50%    75%  97.5%  n_eff   Rhat\n",
       "c[1]         5.33    0.05   0.99   3.35   4.66   5.33   6.02   7.22    413    1.0\n",
       "c[2]        -4.76    0.05    1.0  -6.66  -5.45  -4.77   -4.1  -2.78    413    1.0\n",
       "y[1,1]      8.4e7   13.82 283.06  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    419    1.0\n",
       "y[2,1]      8.4e7   43.32 888.65  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    421    1.0\n",
       "y[3,1]      8.4e7   75.46 1551.8  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    423    1.0\n",
       "y[4,1]      8.4e7   117.7 2432.9  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    427    1.0\n",
       "y[5,1]      8.4e7   169.7 3548.4  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    437    1.0\n",
       "y[6,1]      8.4e7  227.51 4886.5  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    461    1.0\n",
       "y[7,1]      8.4e7  277.54 6399.0  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    532    1.0\n",
       "y[8,1]      8.4e7   289.2 8138.0  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7    792    1.0\n",
       "y[9,1]      8.4e7  243.43  1.1e4  8.4e7  8.4e7  8.4e7  8.4e7  8.4e7   2045    1.0\n",
       "y[10,1]     8.3e7  325.29  1.9e4  8.3e7  8.3e7  8.3e7  8.3e7  8.4e7   3264    1.0\n",
       "y[1,2]     1035.5     9.8 200.81 678.56 894.95 1020.8 1166.5 1456.1    420    1.0\n",
       "y[2,2]     1878.9   17.59 361.19 1240.2 1625.8 1850.2 2113.0 2643.2    422    1.0\n",
       "y[3,2]     2971.7   23.14 477.72 2099.0 2641.7 2937.1 3285.2 3959.4    426    1.0\n",
       "y[4,2]     4777.7   30.24 632.88 3595.5 4348.8 4738.1 5202.6 6055.3    438    1.0\n",
       "y[5,2]     7690.6   37.47 812.01 6133.4 7134.8 7659.4 8246.4 9334.3    470    1.0\n",
       "y[6,2]      1.2e4   41.88 1007.5  1.0e4  1.2e4  1.2e4  1.3e4  1.4e4    579    1.0\n",
       "y[7,2]      2.0e4   38.85 1255.0  1.8e4  1.9e4  2.0e4  2.1e4  2.2e4   1044    1.0\n",
       "y[8,2]      3.2e4   33.02 1812.2  2.9e4  3.1e4  3.2e4  3.3e4  3.6e4   3012    1.0\n",
       "y[9,2]      5.2e4    69.3 3399.1  4.6e4  5.0e4  5.2e4  5.4e4  5.9e4   2406    1.0\n",
       "y[10,2]     8.4e4   215.9 7162.3  7.1e4  7.9e4  8.3e4  8.9e4  9.8e4   1101    1.0\n",
       "y[1,3]     419.95    2.88  58.86  312.2 379.23 416.75 459.03 540.51    419    1.0\n",
       "y[2,3]     1280.6   12.64 259.28 826.35 1098.7 1259.7 1448.0 1831.8    421    1.0\n",
       "y[3,3]     2092.2   17.89 368.11 1432.3 1837.4 2064.0 2333.0 2864.0    423    1.0\n",
       "y[4,3]     3365.0    23.9 495.91 2450.0 3023.5 3330.5 3694.3 4377.3    430    1.0\n",
       "y[5,3]     5414.3   30.59 648.01 4184.7 4973.0 5380.8 5860.1 6719.2    449    1.0\n",
       "y[6,3]     8718.6   36.45 817.66 7147.1 8154.6 8692.7 9274.0  1.0e4    503    1.0\n",
       "y[7,3]      1.4e4   37.59 1006.5  1.2e4  1.3e4  1.4e4  1.5e4  1.6e4    717    1.0\n",
       "y[8,3]      2.3e4   30.86 1310.3  2.0e4  2.2e4  2.3e4  2.4e4  2.5e4   1803    1.0\n",
       "y[9,3]      3.7e4   37.17 2145.6  3.3e4  3.5e4  3.6e4  3.8e4  4.1e4   3332    1.0\n",
       "y[10,3]     5.9e4  110.13 4352.7  5.1e4  5.6e4  5.9e4  6.2e4  6.8e4   1562    1.0\n",
       "y[1,4]     1284.6    1.15  23.42 1240.6 1268.6 1283.7 1300.4 1331.5    417    1.0\n",
       "y[2,4]     2526.4   13.09 268.27 2052.6 2338.3 2505.8 2700.4 3091.9    420    1.0\n",
       "y[3,4]     4850.7   34.44 706.76 3598.0 4357.2 4797.4 5310.4 6345.5    421    1.0\n",
       "y[4,4]     8600.6   63.58 1307.6 6257.5 7693.4 8500.5 9453.4  1.1e4    423    1.0\n",
       "y[5,4]      1.5e4  101.67 2101.7  1.1e4  1.3e4  1.4e4  1.6e4  1.9e4    427    1.0\n",
       "y[6,4]      2.4e4  148.85 3110.9  1.9e4  2.2e4  2.4e4  2.6e4  3.1e4    437    1.0\n",
       "y[7,4]      4.0e4  201.91 4328.4  3.2e4  3.7e4  4.0e4  4.3e4  4.9e4    460    1.0\n",
       "y[8,4]      6.5e4  249.48 5711.9  5.4e4  6.1e4  6.5e4  6.9e4  7.7e4    524    1.0\n",
       "y[9,4]      1.1e5  264.21 7289.8  9.2e4  1.0e5  1.1e5  1.1e5  1.2e5    761    1.0\n",
       "y[10,4]     1.7e5  224.28 9775.6  1.5e5  1.6e5  1.7e5  1.8e5  1.9e5   1900    1.0\n",
       "beta[1]      1.14  5.7e-3   0.12   0.91   1.06   1.14   1.22   1.36    414    1.0\n",
       "beta[2]      0.99  4.3e-3   0.09   0.82   0.93   0.99   1.05   1.16    415    1.0\n",
       "beta[3]      0.88  3.3e-3   0.07   0.74   0.83   0.88   0.92   1.01    416    1.0\n",
       "beta[4]      1.28  7.7e-3   0.16   0.97   1.18   1.28   1.39   1.58    414    1.0\n",
       "beta[5]      0.86  3.3e-3   0.07   0.73   0.82   0.86   0.91   0.99    416    1.0\n",
       "beta[6]       1.2  6.7e-3   0.14   0.93   1.11    1.2   1.29   1.46    414    1.0\n",
       "beta[7]      1.22  7.2e-3   0.15   0.93   1.12   1.22   1.32    1.5    414    1.0\n",
       "beta[8]      0.77  2.8e-3   0.06   0.66   0.73   0.77   0.81   0.88    416    1.0\n",
       "beta[9]      0.37  5.9e-4   0.01   0.34   0.36   0.37   0.37   0.39    430    1.0\n",
       "beta[10]     0.37  5.9e-4   0.01   0.34   0.36   0.37   0.37   0.39    430    1.0\n",
       "x[1]        12.85    0.01   0.23  12.41  12.69  12.84   13.0  13.32    417    1.0\n",
       "x[2]        25.26    0.13   2.68  20.53  23.38  25.06   27.0  30.92    420    1.0\n",
       "x[3]        48.51    0.34   7.07  35.98  43.57  47.97   53.1  63.46    421    1.0\n",
       "x[4]        86.01    0.64  13.08  62.58  76.93  85.01  94.53 113.43    423    1.0\n",
       "x[5]       146.33    1.02  21.02  107.9 131.86 144.79  160.1 189.75    427    1.0\n",
       "x[6]       243.42    1.49  31.11  185.8 222.29 241.31 264.15 306.76    437    1.0\n",
       "x[7]       399.83    2.02  43.28 317.96  370.2  397.8 429.58 487.66    460    1.0\n",
       "x[8]       651.97    2.49  57.12 543.17  612.3 649.92 690.33 769.61    524    1.0\n",
       "x[9]       1058.6    2.64   72.9 920.65 1008.7 1057.2 1106.5 1205.4    761    1.0\n",
       "x[10]      1714.5    2.24  97.76 1526.7 1648.5 1711.6 1781.7 1909.9   1900    1.0\n",
       "lambda[1]    0.84  5.8e-3   0.12   0.62   0.76   0.83   0.92   1.08    419    1.0\n",
       "lambda[2]    2.56    0.03   0.52   1.65    2.2   2.52    2.9   3.66    421    1.0\n",
       "lambda[3]    4.18    0.04   0.74   2.86   3.67   4.13   4.67   5.73    423    1.0\n",
       "lambda[4]    6.73    0.05   0.99    4.9   6.05   6.66   7.39   8.75    430    1.0\n",
       "lambda[5]   10.83    0.06    1.3   8.37   9.95  10.76  11.72  13.44    449    1.0\n",
       "lambda[6]   17.44    0.07   1.64  14.29  16.31  17.39  18.55  20.77    503    1.0\n",
       "lambda[7]    28.1    0.08   2.01  24.23  26.72  28.06  29.42  32.12    717    1.0\n",
       "lambda[8]   45.31    0.06   2.62  40.31  43.54  45.24   47.1  50.54   1803    1.0\n",
       "lambda[9]   73.08    0.07   4.29  65.08  70.05  72.95  75.96  81.63   3332    1.0\n",
       "lambda[10] 117.88    0.22   8.71 101.77 111.72 117.53 123.71 135.58   1562    1.0\n",
       "lp__       928.12    0.03   0.94 925.51 927.73 928.41 928.79 929.06    745    1.0\n",
       "\n",
       "Samples were drawn using NUTS at Tue Nov 24 13:41:58 2020.\n",
       "For each parameter, n_eff is a crude measure of effective sample size,\n",
       "and Rhat is the potential scale reduction factor on split chains (at \n",
       "convergence, Rhat=1)."
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  The findings of this research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### An analysis of potential mistakes\n",
    "\n",
    "- Different traffic components correlate with another which adds noise\n",
    "    - Example: A person uses public transport, goes to the supermarket, goes to a park and travels back home"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion \n",
    "\n",
    "- The results which traffic components have the biggest impact on the spread of COVID-19 are intuitive: \n",
    "    - In places like supermarkets and pharmacies people can hold distance with other people relatively well.\n",
    "    - On contrary, in public transports people easily go very close to other people.\n",
    "    - etc...."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.4. Good articles\n",
    "\n",
    "- https://www.medrxiv.org/content/10.1101/2020.03.03.20030593v1.supplementary-material\n",
    "    - This has a great supplementary material section, and our model is based on that\n",
    "\n",
    "- https://www.fhi.no/en/id/infectious-diseases/coronavirus/coronavirus-modelling-at-the-niph-fhi/\n",
    "    - The Norwegian Institute of Public Health has a great report of modeling COVID-19 with extended SEIR-model \n",
    "\n",
    "- https://www.medrxiv.org/content/10.1101/2020.05.28.20116129v3.full.pdf\n",
    "    - More like nice to read to get some ideas, not direct connection to our model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
